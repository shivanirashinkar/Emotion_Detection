{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf5dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import tkinter as tk\n",
    "import imutils\n",
    "from PIL import ImageTk, Image\n",
    "import tkinter.filedialog as filedialog\n",
    "from tkinter import messagebox\n",
    "import random\n",
    "\n",
    "# Load the pre-trained model for emotion detection\n",
    "model = load_model('C:\\\\Users\\\\91914\\\\Downloads\\\\model.h5')\n",
    "\n",
    "# Define the list of emotions\n",
    "emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "# Emotion-recommendation mapping\n",
    "recommendations = {\n",
    "    'Angry': [\n",
    "        'Take deep breaths and count to 10 before responding.',\n",
    "        'Engage in physical activities like exercise or sports to release pent-up anger.',\n",
    "        'Express your anger through writing or artwork.',\n",
    "    ],\n",
    "    'Disgust': [\n",
    "        'Focus on positive aspects and things you are grateful for.',\n",
    "        'Practice mindfulness or meditation to shift your focus away from negative feelings.',\n",
    "        'Engage in activities that bring you joy and happiness.',\n",
    "    ],\n",
    "    'Fear': [\n",
    "        'Take small steps to face your fears and seek support if needed.',\n",
    "        'Challenge negative thoughts and replace them with positive affirmations.',\n",
    "        'Practice relaxation techniques like deep breathing or progressive muscle relaxation.',\n",
    "    ],\n",
    "    'Happy': [\n",
    "        'Celebrate your happiness and spread positivity to others.',\n",
    "        'Engage in activities that bring you joy and fulfillment.',\n",
    "        'Express gratitude and appreciation for the good things in your life.',\n",
    "    ],\n",
    "    'Sad': [\n",
    "        'Reach out to someone you trust and talk about how you feel.',\n",
    "        'Engage in self-care activities like taking a warm bath or reading a book.',\n",
    "        'Practice self-compassion and allow yourself to grieve and heal.',\n",
    "    ],\n",
    "    'Surprise': [\n",
    "        'Embrace the unexpected and stay open to new experiences.',\n",
    "        'Take it as an opportunity for growth and learning.',\n",
    "        'Embrace the feeling of excitement and anticipation that comes with surprises.',\n",
    "    ],\n",
    "    'Neutral': [\n",
    "        'Take some time for self-reflection and self-care.',\n",
    "        'Engage in activities that bring you peace and relaxation.',\n",
    "        'Explore new hobbies or interests to find inspiration and meaning.',\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Chatbot responses\n",
    "chatbot_responses = [\n",
    "    'Tell me more about it.',\n",
    "    'How does that make you feel?',\n",
    "    'What do you think you should do?',\n",
    "    'I understand. It can be challenging.',\n",
    "    'Is there anything else you would like to share?'\n",
    "]\n",
    "\n",
    "# Function to perform emotion detection on an image\n",
    "def detect_emotion(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (48, 48))\n",
    "    img = img.reshape((1, 48, 48, 1))\n",
    "    img = img.astype('float32') / 255\n",
    "\n",
    "    prediction = model.predict(img)\n",
    "    max_index = np.argmax(prediction[0])\n",
    "    emotion = emotions[max_index]\n",
    "    accuracy = round(prediction[0][max_index] * 100, 2)\n",
    "    return emotion, accuracy\n",
    "\n",
    "# Function to handle image upload\n",
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        img = cv2.imread(file_path)\n",
    "        emotion, accuracy = detect_emotion(img)\n",
    "        result_label.config(text=f'Emotion: {emotion}, Accuracy: {accuracy}%')\n",
    "\n",
    "        # Display the uploaded image in the GUI\n",
    "        display_uploaded_image(img)\n",
    "\n",
    "        # Display recommendations for the detected emotion\n",
    "        display_recommendations(emotion)\n",
    "\n",
    "# Function to start live emotion detection\n",
    "def start_live_detection():\n",
    "    global live_detection_active\n",
    "    live_detection_active = True\n",
    "\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    def update_frame():\n",
    "        ret, frame = video_capture.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        emotion, accuracy = detect_emotion(frame)\n",
    "        result_label.config(text=f'Emotion: {emotion}, Accuracy: {accuracy}%')\n",
    "\n",
    "        # Display the frame in the GUI\n",
    "        display_live_image(frame)\n",
    "\n",
    "        if live_detection_active:\n",
    "            video_label.after(10, update_frame)\n",
    "        else:\n",
    "            video_capture.release()\n",
    "\n",
    "    update_frame()\n",
    "\n",
    "# Function to stop live emotion detection\n",
    "def stop_live_detection():\n",
    "    global live_detection_active\n",
    "    live_detection_active = False\n",
    "\n",
    "# Function to display the recommendations for a specific emotion\n",
    "def display_recommendations(emotion):\n",
    "    recommendations_text.delete('1.0', tk.END)\n",
    "    if emotion in recommendations:\n",
    "        recommendations_text.insert(tk.END, recommendations[emotion])\n",
    "    else:\n",
    "        recommendations_text.insert(tk.END, 'No recommendations available.')\n",
    "\n",
    "# Function to display the uploaded image\n",
    "def display_uploaded_image(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize((250, 250), Image.ANTIALIAS)\n",
    "    img = ImageTk.PhotoImage(img)\n",
    "    uploaded_image_label.config(image=img)\n",
    "    uploaded_image_label.image = img\n",
    "\n",
    "# Function to display the live detection frame\n",
    "def display_live_image(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (250, 250))\n",
    "    img = Image.fromarray(img)\n",
    "    img = ImageTk.PhotoImage(img)\n",
    "    video_label.config(image=img)\n",
    "    video_label.image = img\n",
    "\n",
    "# Function to ask a question to the chatbot\n",
    "def ask_question():\n",
    "    question = chatbot_entry.get().strip()\n",
    "    if question:\n",
    "        chatbot_entry.delete(0, tk.END)\n",
    "        response = random.choice(chatbot_responses)\n",
    "        messagebox.showinfo('Chatbot', f'You asked: {question}\\n\\nChatbot says: {response}')\n",
    "        chatbot_response_label.config(text=response)\n",
    "\n",
    "# Create the GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Detection\")\n",
    "root.geometry(\"900x600\")\n",
    "\n",
    "# Add background image\n",
    "background_image = ImageTk.PhotoImage(file=\"C:\\\\Users\\\\91914\\\\Downloads\\\\cmaq83wr.png\")\n",
    "background_label = tk.Label(root, image=background_image)\n",
    "background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "\n",
    "# Upload Image Section\n",
    "upload_frame = tk.Frame(root)\n",
    "upload_frame.pack(pady=10)\n",
    "\n",
    "upload_label = tk.Label(upload_frame, text='Upload Image:')\n",
    "upload_label.pack(side=tk.LEFT)\n",
    "\n",
    "upload_button = tk.Button(upload_frame, text='Browse', command=upload_image)\n",
    "upload_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "# Live Detection Section\n",
    "live_detection_frame = tk.Frame(root)\n",
    "live_detection_frame.pack(pady=10)\n",
    "\n",
    "live_detection_label = tk.Label(live_detection_frame, text='Live Detection:')\n",
    "live_detection_label.pack(side=tk.LEFT)\n",
    "\n",
    "start_button = tk.Button(live_detection_frame, text='Start', command=start_live_detection)\n",
    "start_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "stop_button = tk.Button(live_detection_frame, text='Stop', command=stop_live_detection)\n",
    "stop_button.pack(side=tk.LEFT)\n",
    "\n",
    "# Result Section\n",
    "result_frame = tk.Frame(root)\n",
    "result_frame.pack(pady=10)\n",
    "\n",
    "result_label = tk.Label(result_frame, text='', font=('Helvetica', 14, 'bold'))\n",
    "result_label.pack()\n",
    "\n",
    "# Recommendations Section\n",
    "recommendations_frame = tk.Frame(root)\n",
    "recommendations_frame.pack(pady=10)\n",
    "\n",
    "recommendations_label = tk.Label(recommendations_frame, text='Recommendation:', font=('Helvetica', 12, 'bold'))\n",
    "recommendations_label.pack(side=tk.LEFT)\n",
    "\n",
    "recommendations_text = tk.Text(recommendations_frame, font=('Helvetica', 12), width=50, height=6)\n",
    "recommendations_text.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "scrollbar = tk.Scrollbar(recommendations_frame, orient=tk.VERTICAL, command=recommendations_text.yview)\n",
    "scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "recommendations_text.configure(yscrollcommand=scrollbar.set)\n",
    "\n",
    "# Chatbot Section\n",
    "chatbot_frame = tk.Frame(root)\n",
    "chatbot_frame.pack(pady=10)\n",
    "\n",
    "chatbot_title_label = tk.Label(chatbot_frame, text=\"I'm here to talk!\", font=('Helvetica', 16, 'bold'))\n",
    "chatbot_title_label.pack()\n",
    "\n",
    "chatbot_entry = tk.Entry(chatbot_frame, font=('Helvetica', 12))\n",
    "chatbot_entry.pack(pady=10)\n",
    "\n",
    "ask_button = tk.Button(chatbot_frame, text='Ask', command=ask_question)\n",
    "ask_button.pack()\n",
    "\n",
    "chatbot_response_label = tk.Label(chatbot_frame, text='', font=('Helvetica', 12))\n",
    "chatbot_response_label.pack(pady=10)\n",
    "\n",
    "# Image Display Section\n",
    "image_display_frame = tk.Frame(root)\n",
    "image_display_frame.pack()\n",
    "\n",
    "uploaded_image_label = tk.Label(image_display_frame)\n",
    "uploaded_image_label.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "video_label = tk.Label(image_display_frame)\n",
    "video_label.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d390e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
